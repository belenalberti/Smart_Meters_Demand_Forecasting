{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):     \n",
    "    assert len(y) == len(y_pred)\n",
    "    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_loss(y_pred, y_true):\n",
    "    return K.sqrt(K.mean(K.square(tf.math.log1p(y_pred) - tf.math.log1p(y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_univariate_loop(dataset):\n",
    "    \n",
    "    random.seed(1)\n",
    "    dataset = df.values\n",
    "    dataset = df.astype('float32')\n",
    "    \n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "    \n",
    "    # split into train and test sets\n",
    "    print('Spliting into train and test')\n",
    "    train_size = int(33600)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    \n",
    "    # reshape into X=t and Y=t+1\n",
    "    look_back = 3\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    testY_copy = testY.copy()\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    \n",
    "    # create and fit the LSTM network\n",
    "    print('Creating and fitting the LSTM network')\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=rmsle_loss, optimizer='adam', metrics = [rmsle_loss])\n",
    "    # simple early stopping\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "    model.fit(trainX, trainY, epochs=15, batch_size=70,validation_split=0.04, verbose=1, shuffle=False, callbacks = [es])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # make predictions\n",
    "    print('Making predictions')\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    \n",
    "    # invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    \n",
    "    #Metrics\n",
    "    print('Calculating metrics')\n",
    "    rmsle_i = rmsle(testY_copy,testPredict)\n",
    "    \n",
    "    return rmsle_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename number 1 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0461 - rmsle_loss: 0.0461 - val_loss: 0.0492 - val_rmsle_loss: 0.0498\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 83us/step - loss: 0.0449 - rmsle_loss: 0.0449 - val_loss: 0.0492 - val_rmsle_loss: 0.0498\n",
      "Epoch 00002: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 2 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 3s 100us/step - loss: 0.0395 - rmsle_loss: 0.0395 - val_loss: 0.0346 - val_rmsle_loss: 0.0354\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 86us/step - loss: 0.0360 - rmsle_loss: 0.0360 - val_loss: 0.0344 - val_rmsle_loss: 0.0353\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 84us/step - loss: 0.0359 - rmsle_loss: 0.0358 - val_loss: 0.0344 - val_rmsle_loss: 0.0353\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 3s 87us/step - loss: 0.0358 - rmsle_loss: 0.0358 - val_loss: 0.0344 - val_rmsle_loss: 0.0354\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 3s 89us/step - loss: 0.0357 - rmsle_loss: 0.0357 - val_loss: 0.0344 - val_rmsle_loss: 0.0354\n",
      "Epoch 00005: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 3 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 3s 106us/step - loss: 0.0483 - rmsle_loss: 0.0483 - val_loss: 0.0869 - val_rmsle_loss: 0.0852\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0470 - rmsle_loss: 0.0470 - val_loss: 0.0869 - val_rmsle_loss: 0.0851\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 96us/step - loss: 0.0470 - rmsle_loss: 0.0470 - val_loss: 0.0870 - val_rmsle_loss: 0.0851\n",
      "Epoch 00003: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 4 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 115us/step - loss: 0.0323 - rmsle_loss: 0.0323 - val_loss: 0.0356 - val_rmsle_loss: 0.0352\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 100us/step - loss: 0.0310 - rmsle_loss: 0.0310 - val_loss: 0.0356 - val_rmsle_loss: 0.0352\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 105us/step - loss: 0.0309 - rmsle_loss: 0.0309 - val_loss: 0.0356 - val_rmsle_loss: 0.0352\n",
      "Epoch 00003: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 5 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 123us/step - loss: 0.0418 - rmsle_loss: 0.0418 - val_loss: 0.0414 - val_rmsle_loss: 0.0409\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 4s 130us/step - loss: 0.0411 - rmsle_loss: 0.0411 - val_loss: 0.0411 - val_rmsle_loss: 0.0405\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 6s 172us/step - loss: 0.0411 - rmsle_loss: 0.0411 - val_loss: 0.0409 - val_rmsle_loss: 0.0403\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 5s 150us/step - loss: 0.0410 - rmsle_loss: 0.0410 - val_loss: 0.0407 - val_rmsle_loss: 0.0401\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 5s 147us/step - loss: 0.0410 - rmsle_loss: 0.0410 - val_loss: 0.0406 - val_rmsle_loss: 0.0400\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 5s 145us/step - loss: 0.0409 - rmsle_loss: 0.0409 - val_loss: 0.0405 - val_rmsle_loss: 0.0398\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 4s 116us/step - loss: 0.0409 - rmsle_loss: 0.0409 - val_loss: 0.0404 - val_rmsle_loss: 0.0397\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 4s 115us/step - loss: 0.0408 - rmsle_loss: 0.0408 - val_loss: 0.0403 - val_rmsle_loss: 0.0396\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 4s 116us/step - loss: 0.0408 - rmsle_loss: 0.0408 - val_loss: 0.0402 - val_rmsle_loss: 0.0395\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 4s 117us/step - loss: 0.0407 - rmsle_loss: 0.0407 - val_loss: 0.0401 - val_rmsle_loss: 0.0394\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 4s 119us/step - loss: 0.0407 - rmsle_loss: 0.0407 - val_loss: 0.0401 - val_rmsle_loss: 0.0394\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 4s 117us/step - loss: 0.0407 - rmsle_loss: 0.0407 - val_loss: 0.0400 - val_rmsle_loss: 0.0393\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 4s 110us/step - loss: 0.0407 - rmsle_loss: 0.0407 - val_loss: 0.0399 - val_rmsle_loss: 0.0392\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 5s 147us/step - loss: 0.0406 - rmsle_loss: 0.0406 - val_loss: 0.0399 - val_rmsle_loss: 0.0392\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 6s 180us/step - loss: 0.0406 - rmsle_loss: 0.0406 - val_loss: 0.0398 - val_rmsle_loss: 0.0391\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 6 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 6s 181us/step - loss: 0.0453 - rmsle_loss: 0.0453 - val_loss: 0.0387 - val_rmsle_loss: 0.0393\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 5s 166us/step - loss: 0.0428 - rmsle_loss: 0.0428 - val_loss: 0.0384 - val_rmsle_loss: 0.0391\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 5s 160us/step - loss: 0.0426 - rmsle_loss: 0.0426 - val_loss: 0.0382 - val_rmsle_loss: 0.0389\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 3s 108us/step - loss: 0.0425 - rmsle_loss: 0.0425 - val_loss: 0.0381 - val_rmsle_loss: 0.0388\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 5s 167us/step - loss: 0.0424 - rmsle_loss: 0.0424 - val_loss: 0.0380 - val_rmsle_loss: 0.0387\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 5s 158us/step - loss: 0.0423 - rmsle_loss: 0.0423 - val_loss: 0.0379 - val_rmsle_loss: 0.0386\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 4s 132us/step - loss: 0.0423 - rmsle_loss: 0.0423 - val_loss: 0.0378 - val_rmsle_loss: 0.0385\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 4s 135us/step - loss: 0.0422 - rmsle_loss: 0.0422 - val_loss: 0.0378 - val_rmsle_loss: 0.0385\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 4s 128us/step - loss: 0.0422 - rmsle_loss: 0.0422 - val_loss: 0.0378 - val_rmsle_loss: 0.0384\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0422 - rmsle_loss: 0.0421 - val_loss: 0.0377 - val_rmsle_loss: 0.0384\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 4s 110us/step - loss: 0.0421 - rmsle_loss: 0.0421 - val_loss: 0.0377 - val_rmsle_loss: 0.0384\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0421 - rmsle_loss: 0.0421 - val_loss: 0.0377 - val_rmsle_loss: 0.0383\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0421 - rmsle_loss: 0.0421 - val_loss: 0.0377 - val_rmsle_loss: 0.0383\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0421 - rmsle_loss: 0.0421 - val_loss: 0.0377 - val_rmsle_loss: 0.0383\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0421 - rmsle_loss: 0.0421 - val_loss: 0.0377 - val_rmsle_loss: 0.0383\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 7 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 131us/step - loss: 0.0513 - rmsle_loss: 0.0513 - val_loss: 0.0405 - val_rmsle_loss: 0.0404\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 4s 112us/step - loss: 0.0486 - rmsle_loss: 0.0486 - val_loss: 0.0403 - val_rmsle_loss: 0.0403\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32252/32252 [==============================] - 3s 95us/step - loss: 0.0484 - rmsle_loss: 0.0484 - val_loss: 0.0403 - val_rmsle_loss: 0.0402\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 3s 95us/step - loss: 0.0483 - rmsle_loss: 0.0483 - val_loss: 0.0402 - val_rmsle_loss: 0.0402\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0482 - rmsle_loss: 0.0482 - val_loss: 0.0402 - val_rmsle_loss: 0.0402\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 3s 96us/step - loss: 0.0481 - rmsle_loss: 0.0481 - val_loss: 0.0402 - val_rmsle_loss: 0.0402\n",
      "Epoch 00006: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 8 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 112us/step - loss: 0.0571 - rmsle_loss: 0.0571 - val_loss: 0.0584 - val_rmsle_loss: 0.0597\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0533 - rmsle_loss: 0.0533 - val_loss: 0.0579 - val_rmsle_loss: 0.0591\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0530 - rmsle_loss: 0.0530 - val_loss: 0.0575 - val_rmsle_loss: 0.0587\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0527 - rmsle_loss: 0.0527 - val_loss: 0.0572 - val_rmsle_loss: 0.0584\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0525 - rmsle_loss: 0.0525 - val_loss: 0.0570 - val_rmsle_loss: 0.0582\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0524 - rmsle_loss: 0.0524 - val_loss: 0.0569 - val_rmsle_loss: 0.0580\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0524 - rmsle_loss: 0.0524 - val_loss: 0.0568 - val_rmsle_loss: 0.0579\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0523 - rmsle_loss: 0.0523 - val_loss: 0.0567 - val_rmsle_loss: 0.0578\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0523 - rmsle_loss: 0.0523 - val_loss: 0.0567 - val_rmsle_loss: 0.0578\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0523 - rmsle_loss: 0.0523 - val_loss: 0.0566 - val_rmsle_loss: 0.0577\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0522 - rmsle_loss: 0.0522 - val_loss: 0.0566 - val_rmsle_loss: 0.0577\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0522 - rmsle_loss: 0.0522 - val_loss: 0.0565 - val_rmsle_loss: 0.0576\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0522 - rmsle_loss: 0.0522 - val_loss: 0.0565 - val_rmsle_loss: 0.0576\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0522 - rmsle_loss: 0.0522 - val_loss: 0.0565 - val_rmsle_loss: 0.0576\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 3s 95us/step - loss: 0.0522 - rmsle_loss: 0.0522 - val_loss: 0.0565 - val_rmsle_loss: 0.0576\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 9 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0561 - rmsle_loss: 0.0561 - val_loss: 0.0504 - val_rmsle_loss: 0.0499\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0523 - rmsle_loss: 0.0523 - val_loss: 0.0503 - val_rmsle_loss: 0.0498\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 94us/step - loss: 0.0522 - rmsle_loss: 0.0522 - val_loss: 0.0502 - val_rmsle_loss: 0.0498\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0521 - rmsle_loss: 0.0521 - val_loss: 0.0502 - val_rmsle_loss: 0.0497\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0520 - rmsle_loss: 0.0520 - val_loss: 0.0502 - val_rmsle_loss: 0.0497\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 3s 95us/step - loss: 0.0519 - rmsle_loss: 0.0519 - val_loss: 0.0502 - val_rmsle_loss: 0.0497\n",
      "Epoch 00006: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 10 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 110us/step - loss: 0.0378 - rmsle_loss: 0.0378 - val_loss: 0.0388 - val_rmsle_loss: 0.0379\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0365 - rmsle_loss: 0.0365 - val_loss: 0.0386 - val_rmsle_loss: 0.0376\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0364 - rmsle_loss: 0.0364 - val_loss: 0.0384 - val_rmsle_loss: 0.0375\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0364 - rmsle_loss: 0.0364 - val_loss: 0.0383 - val_rmsle_loss: 0.0373\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0363 - rmsle_loss: 0.0363 - val_loss: 0.0382 - val_rmsle_loss: 0.0372\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0363 - rmsle_loss: 0.0363 - val_loss: 0.0381 - val_rmsle_loss: 0.0371\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0362 - rmsle_loss: 0.0362 - val_loss: 0.0381 - val_rmsle_loss: 0.0371\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0362 - rmsle_loss: 0.0362 - val_loss: 0.0381 - val_rmsle_loss: 0.0370\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0362 - rmsle_loss: 0.0361 - val_loss: 0.0380 - val_rmsle_loss: 0.0370\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0361 - rmsle_loss: 0.0361 - val_loss: 0.0380 - val_rmsle_loss: 0.0370\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0361 - rmsle_loss: 0.0361 - val_loss: 0.0380 - val_rmsle_loss: 0.0369\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0361 - rmsle_loss: 0.0361 - val_loss: 0.0380 - val_rmsle_loss: 0.0369\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0361 - rmsle_loss: 0.0361 - val_loss: 0.0380 - val_rmsle_loss: 0.0369\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0360 - rmsle_loss: 0.0360 - val_loss: 0.0380 - val_rmsle_loss: 0.0369\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0360 - rmsle_loss: 0.0360 - val_loss: 0.0380 - val_rmsle_loss: 0.0369\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 11 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 110us/step - loss: 0.0539 - rmsle_loss: 0.0539 - val_loss: 0.0433 - val_rmsle_loss: 0.0424\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 92us/step - loss: 0.0506 - rmsle_loss: 0.0506 - val_loss: 0.0432 - val_rmsle_loss: 0.0422\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 93us/step - loss: 0.0501 - rmsle_loss: 0.0501 - val_loss: 0.0433 - val_rmsle_loss: 0.0423\n",
      "Epoch 00003: early stopping\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 12 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0675 - rmsle_loss: 0.0675 - val_loss: 0.0751 - val_rmsle_loss: 0.0730\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 3s 90us/step - loss: 0.0671 - rmsle_loss: 0.0671 - val_loss: 0.0747 - val_rmsle_loss: 0.0726\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 3s 91us/step - loss: 0.0666 - rmsle_loss: 0.0666 - val_loss: 0.0742 - val_rmsle_loss: 0.0721\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 5s 140us/step - loss: 0.0660 - rmsle_loss: 0.0660 - val_loss: 0.0742 - val_rmsle_loss: 0.0721\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 4s 135us/step - loss: 0.0658 - rmsle_loss: 0.0658 - val_loss: 0.0736 - val_rmsle_loss: 0.0715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 3s 104us/step - loss: 0.0657 - rmsle_loss: 0.0657 - val_loss: 0.0733 - val_rmsle_loss: 0.0712\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 3s 103us/step - loss: 0.0657 - rmsle_loss: 0.0657 - val_loss: 0.0731 - val_rmsle_loss: 0.0710\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 3s 99us/step - loss: 0.0656 - rmsle_loss: 0.0656 - val_loss: 0.0731 - val_rmsle_loss: 0.0710\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 4s 111us/step - loss: 0.0656 - rmsle_loss: 0.0656 - val_loss: 0.0730 - val_rmsle_loss: 0.0709\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 4s 118us/step - loss: 0.0655 - rmsle_loss: 0.0655 - val_loss: 0.0730 - val_rmsle_loss: 0.0709\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 4s 116us/step - loss: 0.0655 - rmsle_loss: 0.0655 - val_loss: 0.0729 - val_rmsle_loss: 0.0708\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 4s 132us/step - loss: 0.0654 - rmsle_loss: 0.0654 - val_loss: 0.0729 - val_rmsle_loss: 0.0708\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 4s 136us/step - loss: 0.0654 - rmsle_loss: 0.0654 - val_loss: 0.0728 - val_rmsle_loss: 0.0708\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 4s 133us/step - loss: 0.0654 - rmsle_loss: 0.0654 - val_loss: 0.0728 - val_rmsle_loss: 0.0707\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 4s 137us/step - loss: 0.0653 - rmsle_loss: 0.0653 - val_loss: 0.0727 - val_rmsle_loss: 0.0707\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 13 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 4s 129us/step - loss: 0.0666 - rmsle_loss: 0.0666 - val_loss: 0.0610 - val_rmsle_loss: 0.0592\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 4s 131us/step - loss: 0.0653 - rmsle_loss: 0.0653 - val_loss: 0.0610 - val_rmsle_loss: 0.0591\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 4s 116us/step - loss: 0.0652 - rmsle_loss: 0.0653 - val_loss: 0.0609 - val_rmsle_loss: 0.0591\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 4s 133us/step - loss: 0.0652 - rmsle_loss: 0.0652 - val_loss: 0.0608 - val_rmsle_loss: 0.0590\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 4s 121us/step - loss: 0.0652 - rmsle_loss: 0.0652 - val_loss: 0.0608 - val_rmsle_loss: 0.0589\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 4s 123us/step - loss: 0.0651 - rmsle_loss: 0.0652 - val_loss: 0.0607 - val_rmsle_loss: 0.0589\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 4s 124us/step - loss: 0.0651 - rmsle_loss: 0.0651 - val_loss: 0.0607 - val_rmsle_loss: 0.0588\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 4s 127us/step - loss: 0.0651 - rmsle_loss: 0.0651 - val_loss: 0.0606 - val_rmsle_loss: 0.0588\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 4s 134us/step - loss: 0.0650 - rmsle_loss: 0.0650 - val_loss: 0.0606 - val_rmsle_loss: 0.0588\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 4s 125us/step - loss: 0.0650 - rmsle_loss: 0.0650 - val_loss: 0.0606 - val_rmsle_loss: 0.0587\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 4s 136us/step - loss: 0.0649 - rmsle_loss: 0.0650 - val_loss: 0.0605 - val_rmsle_loss: 0.0587\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 4s 133us/step - loss: 0.0649 - rmsle_loss: 0.0649 - val_loss: 0.0605 - val_rmsle_loss: 0.0586\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 4s 135us/step - loss: 0.0648 - rmsle_loss: 0.0648 - val_loss: 0.0604 - val_rmsle_loss: 0.0586\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 4s 136us/step - loss: 0.0648 - rmsle_loss: 0.0648 - val_loss: 0.0603 - val_rmsle_loss: 0.0585\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 5s 143us/step - loss: 0.0647 - rmsle_loss: 0.0647 - val_loss: 0.0603 - val_rmsle_loss: 0.0585\n",
      "Making predictions\n",
      "Calculating metrics\n",
      "filename number 14 of 14\n",
      "Spliting into train and test\n",
      "Creating and fitting the LSTM network\n",
      "Train on 32252 samples, validate on 1344 samples\n",
      "Epoch 1/15\n",
      "32252/32252 [==============================] - 6s 201us/step - loss: 0.0728 - rmsle_loss: 0.0728 - val_loss: 0.0762 - val_rmsle_loss: 0.0755\n",
      "Epoch 2/15\n",
      "32252/32252 [==============================] - 4s 136us/step - loss: 0.0683 - rmsle_loss: 0.0684 - val_loss: 0.0759 - val_rmsle_loss: 0.0753\n",
      "Epoch 3/15\n",
      "32252/32252 [==============================] - 4s 130us/step - loss: 0.0683 - rmsle_loss: 0.0683 - val_loss: 0.0758 - val_rmsle_loss: 0.0751\n",
      "Epoch 4/15\n",
      "32252/32252 [==============================] - 4s 125us/step - loss: 0.0682 - rmsle_loss: 0.0683 - val_loss: 0.0757 - val_rmsle_loss: 0.0750\n",
      "Epoch 5/15\n",
      "32252/32252 [==============================] - 5s 143us/step - loss: 0.0682 - rmsle_loss: 0.0682 - val_loss: 0.0756 - val_rmsle_loss: 0.0750\n",
      "Epoch 6/15\n",
      "32252/32252 [==============================] - 4s 123us/step - loss: 0.0682 - rmsle_loss: 0.0682 - val_loss: 0.0756 - val_rmsle_loss: 0.0750\n",
      "Epoch 7/15\n",
      "32252/32252 [==============================] - 3s 103us/step - loss: 0.0682 - rmsle_loss: 0.0682 - val_loss: 0.0756 - val_rmsle_loss: 0.0749\n",
      "Epoch 8/15\n",
      "32252/32252 [==============================] - 3s 106us/step - loss: 0.0682 - rmsle_loss: 0.0682 - val_loss: 0.0756 - val_rmsle_loss: 0.0749\n",
      "Epoch 9/15\n",
      "32252/32252 [==============================] - 3s 105us/step - loss: 0.0682 - rmsle_loss: 0.0682 - val_loss: 0.0756 - val_rmsle_loss: 0.0749\n",
      "Epoch 10/15\n",
      "32252/32252 [==============================] - 3s 100us/step - loss: 0.0682 - rmsle_loss: 0.0682 - val_loss: 0.0755 - val_rmsle_loss: 0.0749\n",
      "Epoch 11/15\n",
      "32252/32252 [==============================] - 3s 101us/step - loss: 0.0681 - rmsle_loss: 0.0682 - val_loss: 0.0755 - val_rmsle_loss: 0.0749\n",
      "Epoch 12/15\n",
      "32252/32252 [==============================] - 3s 101us/step - loss: 0.0681 - rmsle_loss: 0.0681 - val_loss: 0.0755 - val_rmsle_loss: 0.0749\n",
      "Epoch 13/15\n",
      "32252/32252 [==============================] - 3s 99us/step - loss: 0.0681 - rmsle_loss: 0.0681 - val_loss: 0.0755 - val_rmsle_loss: 0.0749\n",
      "Epoch 14/15\n",
      "32252/32252 [==============================] - 3s 100us/step - loss: 0.0681 - rmsle_loss: 0.0681 - val_loss: 0.0755 - val_rmsle_loss: 0.0748\n",
      "Epoch 15/15\n",
      "32252/32252 [==============================] - 3s 99us/step - loss: 0.0681 - rmsle_loss: 0.0681 - val_loss: 0.0755 - val_rmsle_loss: 0.0748\n",
      "Making predictions\n",
      "Calculating metrics\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "path = \"/Users/mariabelenalberti/OneDrive - Universidad Torcuato Di Tella/Tesis/code_datasets/1_data_frames/univariate/comfortable_tou\"\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "i = 0\n",
    "rmsle_t = []\n",
    "for filename in all_files:\n",
    "    i = i + 1\n",
    "    print('filename number ' + str(i) + ' of ' + str(len(all_files)))\n",
    "    df = pd.read_csv(filename)\n",
    "    df.set_index(\"tstp\", inplace = True)\n",
    "    rmsle_i = lstm_univariate_loop(df)\n",
    "    rmsle_t.append(round(rmsle_i,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(range(len(rmsle_t)),rmsle_t,color = 'yellow',alpha = 0.5)\n",
    "plt.plot(range(len(rmsle_t)),[min(rmsle_t)]*len(rmsle_t),color = 'grey',linestyle = '--')\n",
    "plt.plot(range(len(rmsle_t)),[round(np.average(rmsle_t),4)]*len(rmsle_t),color = 'grey',linestyle = ':')\n",
    "plt.plot(range(len(rmsle_t)),[max(rmsle_t)]*len(rmsle_t),color = 'grey',linestyle = '-.')\n",
    "plt.yticks([min(rmsle_t),round(np.average(rmsle_t),4),max(rmsle_t)],[str(min(rmsle_t)) + ' (Min)',\n",
    "                                                            str(round(np.average(rmsle_t),4)) + ' (Avg)',\n",
    "                                                                         str(max(rmsle_t))+' (Max)'])\n",
    "plt.title('RMSLE scatter plot',fontsize = 12)\n",
    "plt.xlabel('Households')\n",
    "plt.ylabel('RMSLE')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(rmsle_t,color = 'yellow',alpha = 0.5)\n",
    "plt.axvline(x=min(rmsle_t), color='grey', linestyle='--', linewidth=2)\n",
    "plt.axvline(x=round(np.average(rmsle_t),4), color='grey', linestyle=':', linewidth=2)\n",
    "plt.axvline(x=max(rmsle_t), color='grey', linestyle='-.', linewidth=2)\n",
    "\n",
    "plt.title(\"RMSLE histogram\",fontsize = 12)\n",
    "plt.xlabel('RMSLE')\n",
    "#plt.savefig('/Users/mariabelenalberti/OneDrive - Universidad Torcuato Di Tella/Tesis/plots/4_lstm_uni/RMSLE_comfortable_tou')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
